{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e78301b",
   "metadata": {},
   "source": [
    "# OCI InLAB - Data & AI Team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d441113b",
   "metadata": {},
   "source": [
    "## Primeiros passos com Data Flow Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e947b",
   "metadata": {},
   "source": [
    "Este notebook apresenta os primeiros passos para iniciar a utilização do **_Data Flow Studio_** diretamente do **_OCI Data Science_** e, deste modo, poder construir e executar aplicativos **_Apache Spark_** de forma interativa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355ca9aa",
   "metadata": {},
   "source": [
    "O Oracle desenvolveu uma poderosa biblioteca chamada **_ADS SDK_** (Accelerated Data Science). Esta biblioteca, que é pública, nos permite trabalhar diferentes frentes de acesso, visualizalização, higienização e construção de modelos. Além disso, o ADS SDK nos permite interagir com outros serviços presentes na nuvem Oracle e é a biblioteca que vamos utilizar para iniciar a jornada de trabalho com o Data Flow Studio.\n",
    "\n",
    "Conheça mais sobre o ADS SDK acessando o endereço web: https://docs.oracle.com/en-us/iaas/tools/ads-sdk/latest/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a41267",
   "metadata": {},
   "source": [
    "**Para obter sucesso na execução deste laboratório é preciso definir políticas de acesso dentro da OCI disponíveis em** https://docs.oracle.com/en-us/iaas/data-flow/using/dfs_getting_started.htm#policies-data-flow-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf90393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca ADS e realizando a autenticação\n",
    "import ads\n",
    "\n",
    "ads.set_auth(\"resource_principal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a82d0",
   "metadata": {},
   "source": [
    "O OCI Data Science Notebook conta com algumas variáveis de ambiente que podem ser acessadas utilizando a biblioteca **_os_**. Além disso, vamos definir um local (bucket) para armazenar os logs gerados pelas sessões do Data Flow Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98deb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "compartment_id = os.environ.get(\"NB_SESSION_COMPARTMENT_OCID\") #identificando o compartimento da OCI em utilização\n",
    "logs_bucket_uri = \"oci://nome-do-seu-bucket@namespace-da-tenancy\" #definindo o bucket para armazenamento de logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d906e",
   "metadata": {},
   "source": [
    "Para a criação da sessão do Data Flow Studio vamos definir uma curta função para manipular os argumentos e parâmetros da sessão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1acf20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def prepare_command(command: dict) -> str:\n",
    "    \"\"\"Converts dictionary command to the string formatted commands.\"\"\"\n",
    "    return f\"'{json.dumps(command)}'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f16793",
   "metadata": {},
   "source": [
    "Após a execução das etapas acima, carregamos o **_SparkMagic_**. O SparkMagic utiliza o **_Apache Livy_** para execução de sessões interativas de cargas de trabalho Apache Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015920f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dataflow.magics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f77299",
   "metadata": {},
   "source": [
    "Após a carga do SparkMagic podemos executar comandos \"mágicos\" diretamente das células do notebook. Vamos explorar as opções disponíveis executando **_%help_**. Será exibida uma lista de comandos suportados pelo SparkMagic e exemplos de utilização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0187e694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table>\n",
       "  <tr>\n",
       "    <th style=\"text-align:left\">Magic</th>\n",
       "    <th style=\"text-align:left\">Example</th>\n",
       "    <th style=\"text-align:left\">Explanation</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>create_session</td>\n",
       "    <td  style=\"text-align:left\">%create_session -l python -c '{\"compartmentId\":\"Data Flow Run resource compartment OCID\",\"displayName\":\"SessionApp\",\"sparkVersion\":\"3.2.1\",\"driverShape\":\"VM.Standard2.1\",\"executorShape\":\"VM.Standard2.1\",\"numExecutors\":1,\"archiveUri\":\"Object Storage URL for Data Flow zip archive.\",\"metastoreId\":\"optional metastore OCID\",\"configuration\":{      \"spark.archives\":\"oci://bucket@namespace/path/to/conda/pack\",      #optional property to use Dataflow 'Run' resource to access OCI resources.\n",
       "      \"dataflow.auth\":\"resource_principal\"   }}'</td>\n",
       "    <td style=\"text-align:left\">Creates new session by providing session details.<br/><br/><b>Example command for Flex shapes :</b><br/>\n",
       "    %create_session -l python -c '{\"compartmentId\":\"Data Flow Run resource compartment OCID\",\"displayName\":\"SessionApp\",\"sparkVersion\":\"3.2.1\",\"driverShape\":\"VM.Standard.E4.Flex\",\"executorShape\":\"VM.Standard.E4.Flex\",\"numExecutors\":1,\"driverShapeConfig\":{\"ocpus\":1,\"memoryInGBs\":16},\"executorShapeConfig\":{\"ocpus\":1,\"memoryInGBs\":16}}'\n",
       "    <br/><br/><b>Example command for Spark dynamic allocation :</b><br/>\n",
       "    %create_session -l python -c '{\"compartmentId\":\"Data Flow Run resource compartment OCID\",\"displayName\":\"SessionApp\",\"sparkVersion\":\"3.2.1\",\"driverShape\":\"VM.Standard2.1\",\"executorShape\":\"VM.Standard2.1\",\"numExecutors\":1,\"configuration\":{ \"spark.dynamicAllocation.enabled\":\"true\", \"spark.dynamicAllocation.shuffleTracking.enabled\":\"true\", \"spark.dynamicAllocation.minExecutors\":\"1\", \"spark.dynamicAllocation.maxExecutors\":\"4\", \"spark.dynamicAllocation.executorIdleTimeout\":\"60\", \"spark.dynamicAllocation.schedulerBacklogTimeout\":\"60\", \"spark.dataflow.dynamicAllocation.quotaPolicy\":\"min\" }}'\n",
       "    </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>activate_session</td>\n",
       "    <td  style=\"text-align:left\">%activate_session -l python -c '{\"compartmentId\":\"Data Flow Run resource compartment OCID\",\"displayName\":\"SessionApp\",\"applicationId\":\"Existing sessionId to activate.\"}'</td>\n",
       "    <td  style=\"text-align:left\">Activate session by providing existing sessionId.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>use_session</td>\n",
       "    <td  style=\"text-align:left\">%use_session -s {sessionId}</td>\n",
       "    <td  style=\"text-align:left\">To use already existing active session.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>status</td>\n",
       "    <td  style=\"text-align:left\">%status</td>\n",
       "    <td  style=\"text-align:left\">Outputs current session status.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>update_session</td>\n",
       "    <td  style=\"text-align:left\">%update_session -i '{\"maxDurationInMinutes\": 4896,\"idleTimeoutInMinutes\": 4888}'</td>\n",
       "    <td  style=\"text-align:left\">Updates current active session[not session config] for max duration or idle time out.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>stop_session</td>\n",
       "    <td  style=\"text-align:left\">%stop_session</td>\n",
       "    <td  style=\"text-align:left\">Stops current active session. One active session should be associated with current notebook to stop.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>config</td>\n",
       "    <td  style=\"text-align:left\">%config</td>\n",
       "    <td  style=\"text-align:left\">Outputs current session configuration.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>configure_session</td>\n",
       "    <td  style=\"text-align:left\">%configure_session -i '{\"driverShape\": \"VM.Standard2.1\", \"executorShape\": \"VM.Standard2.1\", \"numExecutors\": 1}'</td>\n",
       "    <td  style=\"text-align:left\">Configures the session creation parameters. The force flag -f is mandatory for immediate effect of the config change, in that case session will be dropped and recreated.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>spark</td>\n",
       "    <td  style=\"text-align:left\">%%spark -o df<br/>df = spark.read.parquet('...</td>\n",
       "    <td  style=\"text-align:left\">Executes spark commands.<br/>\n",
       "    Parameters:\n",
       "      <ul>\n",
       "        <li>-o VAR_NAME: The Spark dataframe of name VAR_NAME will be available in the %%local Python context as a\n",
       "          <a href=\"http://pandas.pydata.org/\">Pandas</a> dataframe with the same name.</li>\n",
       "        <li>-m METHOD: Sample method, either <tt>take</tt> or <tt>sample</tt>.</li>\n",
       "        <li>-n MAXROWS: The maximum number of rows of a dataframe that will be pulled from Livy to Jupyter.\n",
       "            If this number is negative, then the number of rows will be unlimited.</li>\n",
       "        <li>-r FRACTION: Fraction used for sampling.</li>\n",
       "      </ul>\n",
       "    </td>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4588b17e",
   "metadata": {},
   "source": [
    "A seguir vamos criar um sessão do Data Flow Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c89d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = prepare_command(\n",
    "    {\n",
    "        \"compartmentId\": compartment_id,\n",
    "        \"displayName\": \"DataFlow Studio Primeira Sessão\",\n",
    "        \"language\": \"PYTHON\",\n",
    "        \"sparkVersion\": \"3.2.1\",\n",
    "        \"numExecutors\": 1,\n",
    "        \"driverShape\": \"VM.Standard.E4.Flex\",\n",
    "        \"executorShape\": \"VM.Standard.E4.Flex\",\n",
    "        \"driverShapeConfig\": {\"ocpus\": 1, \"memoryInGBs\": 16},\n",
    "        \"executorShapeConfig\": {\"ocpus\": 1, \"memoryInGBs\": 16},\n",
    "        \"logsBucketUri\": logs_bucket_uri,\n",
    "        \"type\": \"SESSION\",\n",
    "        \"configuration\": {\n",
    "            \"spark.archives\": custom_conda_environment_uri,\n",
    "            \"spark.jars.ivy\": \"/opt/spark/work-dir/conda/.ivy2\",\n",
    "            \"spark.jars\": \"oci://nome-do-seu-bucket@namespace-da-tenancy/seu-jar.jar\",\n",
    "        },\n",
    "        \"privateEndpointId\":\"privateEndpointId\",\n",
    "        \"metastoreId\":\"metastoreId\",\n",
    "    }\n",
    ") \n",
    "%create_session -l python -c $command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e54921",
   "metadata": {},
   "source": [
    "Você pode explorar outros exemplos de criação de sessão e explicação sobre cada parâmetros acesso o site https://docs.oracle.com/en-us/iaas/tools/ads-sdk/latest/user_guide/apachespark/dataflow-spark-magic.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdcd08e",
   "metadata": {},
   "source": [
    "Neste notebook é utilizada uma sessão já existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4895a6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Active Session .. ocid1.dataflowrun.oc1.sa-saopaulo-1.antxeljrtsbrckqausxu55q7cdh4aprkp7pgfzcgaqlbyp7e4kfosbtmsp3q\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ac301baa944dd084e6949690ae0ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster is ready..\n",
      "Starting Spark application..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>Session ID</th><th>Kind</th><th>State</th><th>Current session</th></tr><tr><td>ocid1.dataflowapplication.oc1.sa-saopaulo-1.antxeljrtsbrckqadnztrjhiprmtnccq6ggl5giu2c4hd6ymyza2xangogka</td><td>pyspark</td><td>IN_PROGRESS</td><td><a target=\"_blank\" href=\"https://console.us-phoenix-1.oraclecloud.com/data-flow/runs/details/ocid1.dataflowrun.oc1.sa-saopaulo-1.antxeljrtsbrckqausxu55q7cdh4aprkp7pgfzcgaqlbyp7e4kfosbtmsp3q?region=sa-saopaulo-1\">Dataflow Run</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "SparkContext available as 'sc'.\n"
     ]
    }
   ],
   "source": [
    "%use_session -s {'sua-sessão-existente-id'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f66aa1a",
   "metadata": {},
   "source": [
    "Após a criação ou ativação de uma sessão já existe, são disponibilizados dois novos _magic commands_. Estes são: **_%%spark_** e também o **_%%sc_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daf1860c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A versão do Spark em execução no cluster do Data Flow Studio é: 3.2.1"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "print(f'A versão do Spark em execução no cluster do Data Flow Studio é: {sc.version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e26378",
   "metadata": {},
   "source": [
    "A partir daí podemos executar operações spark, sc e sql diretamente no cluster do Data Flow Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b214079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First element of numbers is 4\n",
      "The RDD, numbers, has the following description\n",
      "b'(2) ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274 []'"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "numbers = sc.parallelize([4, 3, 2, 1])\n",
    "print(f\"First element of numbers is {numbers.first()}\")\n",
    "print(f\"The RDD, numbers, has the following description\\n{numbers.toDebugString()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31af7f42",
   "metadata": {},
   "source": [
    "Podemos criar um dataframe spark e realizar operações sobre ele. Neste exemplo é utilizado o [NYC Taxi and Limousine Commission (TLC) Data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page).\n",
    "Trata-se de um dataset de aproximadamente 488Mb com dados do ano de 2022 do mês de janeiro até outubro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a5b0ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2022-10-01 00:03:41|  2022-10-01 00:18:39|            1.0|          1.7|       1.0|                 N|         249|         107|           1|        9.5|  3.0|    0.5|      2.65|         0.0|                  0.3|       15.95|                 2.5|        0.0|\n",
      "|       2| 2022-10-01 00:14:30|  2022-10-01 00:19:48|            2.0|         0.72|       1.0|                 N|         151|         238|           2|        5.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         9.3|                 2.5|        0.0|\n",
      "|       2| 2022-10-01 00:27:13|  2022-10-01 00:37:41|            1.0|         1.74|       1.0|                 N|         238|         166|           1|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|                 0.0|        0.0|\n",
      "|       1| 2022-10-01 00:32:53|  2022-10-01 00:38:55|            0.0|          1.3|       1.0|                 N|         142|         239|           1|        6.5|  3.0|    0.5|      2.05|         0.0|                  0.3|       12.35|                 2.5|        0.0|\n",
      "|       1| 2022-10-01 00:44:55|  2022-10-01 00:50:21|            0.0|          1.0|       1.0|                 N|         238|         166|           1|        6.0|  0.5|    0.5|       1.8|         0.0|                  0.3|         9.1|                 0.0|        0.0|\n",
      "|       1| 2022-10-01 00:22:52|  2022-10-01 00:52:14|            1.0|          6.8|       1.0|                 Y|         186|          41|           2|       25.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        29.3|                 2.5|        0.0|\n",
      "|       2| 2022-10-01 00:33:19|  2022-10-01 00:44:51|            3.0|         1.88|       1.0|                 N|         162|         145|           2|       10.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        14.3|                 2.5|        0.0|\n",
      "|       1| 2022-10-01 00:02:42|  2022-10-01 00:50:01|            1.0|         12.2|       1.0|                 N|         100|          22|           1|       41.0|  3.0|    0.5|       3.0|         0.0|                  0.3|        47.8|                 2.5|        0.0|\n",
      "|       2| 2022-10-01 00:06:35|  2022-10-01 00:24:38|            1.0|         7.79|       1.0|                 N|         138|         112|           1|       23.5|  0.5|    0.5|      4.96|         0.0|                  0.3|       31.01|                 0.0|       1.25|\n",
      "|       2| 2022-10-01 00:29:25|  2022-10-01 00:43:15|            1.0|         4.72|       1.0|                 N|         145|          75|           1|       14.5|  0.5|    0.5|       1.5|         0.0|                  0.3|        19.8|                 2.5|        0.0|\n",
      "|       1| 2022-10-01 00:01:55|  2022-10-01 00:20:16|            1.0|          8.8|       1.0|                 N|         138|         236|           1|       26.0| 4.25|    0.5|      5.64|        6.55|                  0.3|       43.24|                 2.5|       1.25|\n",
      "|       1| 2022-10-01 00:27:48|  2022-10-01 00:59:50|            1.0|          8.6|       1.0|                 N|         140|          36|           1|       29.5|  3.0|    0.5|       6.0|         0.0|                  0.3|        39.3|                 2.5|        0.0|\n",
      "|       1| 2022-10-01 00:05:27|  2022-10-01 00:35:33|            4.0|         12.0|       1.0|                 N|          70|         230|           2|       36.5|  3.0|    0.5|       0.0|        6.55|                  0.3|       46.85|                 2.5|        0.0|\n",
      "|       1| 2022-10-01 00:38:53|  2022-10-01 00:48:13|            2.0|          1.4|       1.0|                 N|         230|          68|           1|        8.5|  3.0|    0.5|      3.05|         0.0|                  0.3|       15.35|                 2.5|        0.0|\n",
      "|       2| 2022-10-01 00:24:40|  2022-10-01 00:30:23|            1.0|         0.76|       1.0|                 N|          79|         113|           1|        5.5|  0.5|    0.5|      0.93|         0.0|                  0.3|       10.23|                 2.5|        0.0|\n",
      "|       2| 2022-10-01 00:32:22|  2022-10-01 00:58:55|            1.0|          7.8|       1.0|                 N|         113|         116|           1|       26.5|  0.5|    0.5|      6.06|         0.0|                  0.3|       36.36|                 2.5|        0.0|\n",
      "|       2| 2022-10-01 00:17:08|  2022-10-01 00:30:50|            2.0|          2.9|       1.0|                 N|          13|         249|           1|       12.0|  0.5|    0.5|       2.8|         0.0|                  0.3|        18.6|                 2.5|        0.0|\n",
      "|       2| 2022-10-01 00:32:14|  2022-10-01 00:44:35|            1.0|         1.71|       1.0|                 N|         249|          79|           1|        9.0|  0.5|    0.5|      2.56|         0.0|                  0.3|       15.36|                 2.5|        0.0|\n",
      "|       2| 2022-10-01 00:09:24|  2022-10-01 00:21:45|            1.0|          2.3|       1.0|                 N|          48|         249|           1|       10.0|  0.5|    0.5|      2.76|         0.0|                  0.3|       16.56|                 2.5|        0.0|\n",
      "|       2| 2022-10-01 00:22:29|  2022-10-01 00:33:53|            2.0|         1.67|       1.0|                 N|         249|         224|           1|        8.5|  0.5|    0.5|      2.46|         0.0|                  0.3|       14.76|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "df_nyc_tlc = spark.read.parquet(\"oci://arquivos@id3kyspkytmr/nyc_tlc/\", header=False, inferSchema=True)\n",
    "df_nyc_tlc.show()\n",
    "df_nyc_tlc.createOrReplaceTempView(\"nyc_tlc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb32675",
   "metadata": {},
   "source": [
    "Após a criação da tempView podemos rodar consultas baseadas em SQL e armazenar a saída num objeto dataframe usando o parâmetro **_-o_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d110d35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>payment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendorID  passenger_count  trip_distance  payment_type\n",
       "0         1              1.0           1.70             1\n",
       "1         2              2.0           0.72             2\n",
       "2         2              1.0           1.74             1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%spark -c sql -o df_nyc_tlc\n",
    "SELECT vendorID, passenger_count, trip_distance, payment_type FROM nyc_tlc LIMIT 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ee9be7",
   "metadata": {},
   "source": [
    "Além disso, também é possivel executar comandos **_Delta Lake_** para interagir sobre os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af11033d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "df_nyc_tlc.write.format(\"delta\").save(\"oci://arquivos@id3kyspkytmr/nyc_tlc/delta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa3e073",
   "metadata": {},
   "source": [
    "Por fim, também há suporte ao **_Hive Metastore_**. Na nuvem Oracle a OCI disponibiliza o **_OCI Data Catalog_** e o mesmo conta com um Metastore que pode ser utilizado. Acesse https://docs.oracle.com/en-us/iaas/data-flow/using/hive-metastore.htm para detalhes completos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d467fc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%spark -c sql\n",
    "CREATE DATABASE studio;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fd60b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%spark -c sql\n",
    "USE studio;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de8e7f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%spark -c sql\n",
    "CREATE TABLE nyc_tlc_table AS (SELECT * FROM nyc_tlc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ba21095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>studio</td>\n",
       "      <td>nyc_tlc_table</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>nyc_tlc</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  namespace      tableName  isTemporary\n",
       "0    studio  nyc_tlc_table        False\n",
       "1                  nyc_tlc         True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%spark -c sql\n",
    "SHOW TABLES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd59a15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33003832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(1)\n",
       "0  33003832"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%spark -c sql\n",
    "SELECT COUNT(1) FROM nyc_tlc_table;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1eba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark32_p38_cpu_v2]",
   "language": "python",
   "name": "conda-env-pyspark32_p38_cpu_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
